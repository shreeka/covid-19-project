{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b'From https://github.com/CSSEGISandData/COVID-19\\n   29b85c49..5d49f1e6  master     -> origin/master\\n   23632359..b54d1130  web-data   -> origin/web-data\\n'\n",
      "out : b'Updating 29b85c49..5d49f1e6\\nFast-forward\\n README.md | 1 +\\n 1 file changed, 1 insertion(+)\\n'\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/data/get_data.py\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def get_john_hopkins_data():\n",
    "    ''' \n",
    "        Git repo John Hopkins data : https://github.com/CSSEGISandData/COVID-19.git\n",
    "        Get john hopkins data by a git pull request\n",
    "        Result is stored in the predefined csv structure\n",
    "    '''\n",
    "    git_pull = subprocess.Popen(\"/usr/bin/git pull\",\n",
    "                                cwd=os.path.dirname('../data/raw/COVID-19/'),\n",
    "                                shell=True,\n",
    "                                stdout=subprocess.PIPE,\n",
    "                                stderr=subprocess.PIPE)\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_john_hopkins_data()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 59850\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/data/process_JH_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def transform_relational_JH_data():\n",
    "    ''' Transforms the COVID data into a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path = '../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base = pd_raw.rename(columns={'Country/Region': 'country',\n",
    "                                          'Province/State': 'state'})\n",
    "\n",
    "    pd_data_base['state'] = pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base = pd_data_base.drop(['Lat', 'Long'], axis=1)\n",
    "\n",
    "    pd_relational_model = pd_data_base.set_index(['state', 'country']) \\\n",
    "        .T                              \\\n",
    "        .stack(level=[0, 1])             \\\n",
    "        .reset_index()                  \\\n",
    "        .rename(columns={'level_0': 'date',\n",
    "                         0: 'confirmed'},\n",
    "                )\n",
    "\n",
    "    pd_relational_model['date'] = pd_relational_model.date.astype(\n",
    "        'datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv(\n",
    "        '../data/processed/COVID_relational_confirmed.csv', sep=';', index=False)\n",
    "    print(' Number of rows stored: ' + str(pd_relational_model.shape[0]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    transform_relational_JH_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Filter data and doubling rate calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date state country  confirmed  confirmed_filtered  confirmed_DR  \\\n",
      "44995 2020-08-29    no   Nepal    37340.0             37469.2     40.244800   \n",
      "44996 2020-08-30    no   Nepal    38561.0             38469.2     35.584165   \n",
      "44997 2020-08-31    no   Nepal    39460.0             39507.8     36.277044   \n",
      "44998 2020-09-01    no   Nepal    40529.0             40566.4     40.159214   \n",
      "44999 2020-09-02    no   Nepal    41649.0             41625.0     37.045226   \n",
      "\n",
      "       confirmed_filtered_DR  \n",
      "44995              36.208275  \n",
      "44996              37.309699  \n",
      "44997              37.753426  \n",
      "44998              37.683069  \n",
      "44999              38.320801  \n"
     ]
    }
   ],
   "source": [
    "# %load ../src/features/build_features.py\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1, 2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array) == 3\n",
    "    reg.fit(X, y)\n",
    "    intercept = reg.intercept_\n",
    "    slope = reg.coef_\n",
    "\n",
    "    return intercept / slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input, column='confirmed', window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree = 1\n",
    "    df_result = df_input\n",
    "\n",
    "    filter_in = df_input[column].fillna(0)\n",
    "\n",
    "    result = signal.savgol_filter(np.array(filter_in),\n",
    "                                  window,  # window size used for filtering\n",
    "                                  1)\n",
    "    df_result[str(column + '_filtered')] = result\n",
    "    return df_result\n",
    "\n",
    "\n",
    "def rolling_reg(df_input, col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back = 3\n",
    "    result = df_input[col].rolling(\n",
    "        window=days_back,\n",
    "        min_periods=days_back).apply(get_doubling_time_via_regression, raw=False)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_filtered_data(df_input, filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain = set(['state', 'country', filter_on])\n",
    "    assert must_contain.issubset(set(\n",
    "        df_input.columns)), ' Error in get_filtered_data when not all columns in data frame'\n",
    "\n",
    "    #get a copy here otherwise the filter_on column will be overwritten\n",
    "    df_output = df_input.copy()\n",
    "\n",
    "    pd_filtered_result = df_output[['state', 'country', filter_on]].groupby(\n",
    "        ['state', 'country']).apply(savgol_filter)  \n",
    "\n",
    "    df_output = pd.merge(df_output, pd_filtered_result[[str(\n",
    "        filter_on + '_filtered')]], left_index=True, right_index=True, how='left')\n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "def get_doubling_rate(df_input, filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain = set(['state', 'country', filter_on])\n",
    "    assert must_contain.issubset(set(\n",
    "        df_input.columns)), ' Error in get_filtered_data when not all columns in data frame'\n",
    "\n",
    "    pd_DR_result = df_input.groupby(['state', 'country']).apply(\n",
    "        rolling_reg, filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result = pd_DR_result.rename(columns={filter_on: filter_on + '_DR',\n",
    "                                                'level_2': 'index'})\n",
    "\n",
    "    # merge dataframes on the index of the big table and on the index column after groupby\n",
    "    df_output = pd.merge(df_input, pd_DR_result[['index', str(\n",
    "        filter_on + '_DR')]], left_index=True, right_on=['index'], how='left')\n",
    "    df_output = df_output.drop(columns=['index'])\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "   # test_data_reg = np.array([2, 4, 6])\n",
    "   # result = get_doubling_time_via_regression(test_data_reg)\n",
    "   # print('the test slope is: ' + str(result))\n",
    "\n",
    "    pd_JH_data = pd.read_csv(\n",
    "        '../data/processed/COVID_relational_confirmed.csv', sep=';', parse_dates=[0])\n",
    "    pd_JH_data = pd_JH_data.sort_values('date', ascending=True).copy()\n",
    "\n",
    "    pd_result_larg = get_filtered_data(pd_JH_data)\n",
    "    pd_result_larg = get_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg = get_doubling_rate(pd_result_larg, 'confirmed_filtered')\n",
    "\n",
    "    mask = pd_result_larg['confirmed'] > 100\n",
    "    pd_result_larg['confirmed_filtered_DR'] = pd_result_larg['confirmed_filtered_DR'].where(\n",
    "        mask, other=np.NaN)\n",
    "    pd_result_larg.to_csv(\n",
    "        '../data/processed/COVID_final_set.csv', sep=';', index=False)\n",
    "    print(pd_result_larg[pd_result_larg['country'] == 'Nepal'].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prototype Visual Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " Warning: This is a development server. Do not use app.run_server\n",
      " in production, use a production WSGI server like gunicorn instead.\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/visualization/visualize.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "\n",
    "df_input_large = pd.read_csv('../data/processed/COVID_final_set.csv', sep=';')\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    # COVID-19 Dashboard\n",
    "\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "       #### Multi-Select Country for visualization\n",
    "    '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[{'label': each, 'value': each}\n",
    "                 for each in df_input_large['country'].unique()],\n",
    "        value=['US', 'Germany', 'Nepal'],  # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "        #### Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='doubling_time',\n",
    "        options=[\n",
    "            {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "            {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "            {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "            {'label': 'Timeline Doubling Rate Filtered',\n",
    "             'value': 'confirmed_filtered_DR'},\n",
    "        ],\n",
    "        value='confirmed',\n",
    "        multi=False\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_window_slope')\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "     Input('doubling_time', 'value')])\n",
    "def update_figure(country_list, show_doubling):\n",
    "\n",
    "    if ('confirmed_DR' in show_doubling) or ('confirmed_filtered_DR' in show_doubling):\n",
    "        my_yaxis = {'type': \"log\",\n",
    "                    'title': 'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "                    }\n",
    "    else:\n",
    "        my_yaxis = {'type': \"log\",\n",
    "                    'title': 'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "                    }\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot = df_input_large[df_input_large['country'] == each]\n",
    "\n",
    "        if show_doubling == 'confirmed_filtered_DR':\n",
    "            df_plot = df_plot[['state', 'country', 'confirmed', 'confirmed_filtered', 'confirmed_DR',\n",
    "                               'confirmed_filtered_DR', 'date']].groupby(['country', 'date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot = df_plot[['state', 'country', 'confirmed', 'confirmed_filtered', 'confirmed_DR',\n",
    "                               'confirmed_filtered_DR', 'date']].groupby(['country', 'date']).agg(np.sum).reset_index()\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                           y=df_plot[show_doubling],\n",
    "                           mode='markers+lines',\n",
    "                           opacity=0.9,\n",
    "                           name=each\n",
    "                           )\n",
    "                      )\n",
    "\n",
    "    return {\n",
    "        'data': traces,\n",
    "        'layout': dict(\n",
    "            width=1280,\n",
    "            height=720,\n",
    "\n",
    "            xaxis={'title': 'Timeline',\n",
    "                   'tickangle': -45,\n",
    "                   'nticks': 20,\n",
    "                   'tickfont': dict(size=14, color=\"#7f7f7f\"),\n",
    "                   },\n",
    "\n",
    "            yaxis=my_yaxis\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
